{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8HRHPSkUIXbDGH+SUolHb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ma7moudYasser/MachineLearningForEru/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n"
      ],
      "metadata": {
        "id": "VNFvvcSOv8FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data cleaning"
      ],
      "metadata": {
        "id": "Zjhg-_omwAYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZHa9RfVv2c3",
        "outputId": "26848d18-2b69-4ee1-96d3-343f40b394c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            "       A    B     C\n",
            "0    1.0  5.0  10.0\n",
            "1    2.0  NaN  11.0\n",
            "2    NaN  7.0  12.0\n",
            "3    4.0  8.0   NaN\n",
            "4  100.0  9.0  14.0\n",
            "\n",
            "Data after imputing missing values:\n",
            "        A     B      C\n",
            "0    1.00  5.00  10.00\n",
            "1    2.00  7.25  11.00\n",
            "2   26.75  7.00  12.00\n",
            "3    4.00  8.00  11.75\n",
            "4  100.00  9.00  14.00\n",
            "\n",
            "Outlier bounds:\n",
            "-35.125\n",
            "63.875\n",
            "\n",
            "Data after removing outliers:\n",
            "       A     B      C\n",
            "0   1.00  5.00  10.00\n",
            "1   2.00  7.25  11.00\n",
            "2  26.75  7.00  12.00\n",
            "3   4.00  8.00  11.75\n",
            "\n",
            "Final cleaned data:\n",
            "       A     B      C\n",
            "0   1.00  5.00  10.00\n",
            "1   2.00  7.25  11.00\n",
            "2  26.75  7.00  12.00\n",
            "3   4.00  8.00  11.75\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Sample data with missing values and outliers\n",
        "data = {\n",
        "    'A': [1, 2, np.nan, 4, 100],  # 100 is an outlier\n",
        "    'B': [5, np.nan, 7, 8, 9],\n",
        "    'C': [10, 11, 12, np.nan, 14]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original data:\")\n",
        "print(df)\n",
        "\n",
        "# Handling missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "print(\"\\nData after imputing missing values:\")\n",
        "print(df_imputed)\n",
        "\n",
        "# Handling outliers (using IQR method)\n",
        "Q1 = df_imputed['A'].quantile(0.25)\n",
        "Q3 = df_imputed['A'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(\"\\nOutlier bounds:\")\n",
        "print(lower_bound)\n",
        "print(upper_bound)\n",
        "\n",
        "df_clean = df_imputed[(df_imputed['A'] >= lower_bound) & (df_imputed['A'] <= upper_bound)]\n",
        "\n",
        "print(\"\\nData after removing outliers:\")\n",
        "print(df_clean)\n",
        "\n",
        "# Remove duplicates\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "\n",
        "print(\"\\nFinal cleaned data:\")\n",
        "print(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Integration"
      ],
      "metadata": {
        "id": "5bv1x7dG5pmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample datasets\n",
        "data1 = pd.DataFrame({\n",
        "    'ID': [1, 2, 3],\n",
        "    'Name': ['John', 'Jane', 'Bob'],\n",
        "    'Age': [25, 30, 35]\n",
        "})\n",
        "\n",
        "data2 = pd.DataFrame({\n",
        "    'ID': [2, 3, 4],\n",
        "    'City': ['New York', 'London', 'Paris'],\n",
        "    'Salary': [50000, 60000, 55000]\n",
        "})\n",
        "\n",
        "print(\"Dataset 1:\")\n",
        "print(data1)\n",
        "print(\"\\nDataset 2:\")\n",
        "print(data2)\n",
        "\n",
        "# Merge datasets based on 'ID'\n",
        "merged_data = pd.merge(data1, data2, on='ID', how='outer')\n",
        "\n",
        "print(\"\\nMerged Dataset:\")\n",
        "print(merged_data)\n",
        "\n",
        "# Fill missing values\n",
        "merged_data['City'].fillna('Unknown', inplace=True)\n",
        "merged_data['Salary'].fillna(merged_data['Salary'].mean(), inplace=True)\n",
        "\n",
        "print(\"\\nFinal Integrated Dataset:\")\n",
        "print(merged_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzgr9Qoc4bo4",
        "outputId": "3368b915-c35d-468d-aeb8-eacc3d234284"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1:\n",
            "   ID  Name  Age\n",
            "0   1  John   25\n",
            "1   2  Jane   30\n",
            "2   3   Bob   35\n",
            "\n",
            "Dataset 2:\n",
            "   ID      City  Salary\n",
            "0   2  New York   50000\n",
            "1   3    London   60000\n",
            "2   4     Paris   55000\n",
            "\n",
            "Merged Dataset:\n",
            "   ID  Name   Age      City   Salary\n",
            "0   1  John  25.0       NaN      NaN\n",
            "1   2  Jane  30.0  New York  50000.0\n",
            "2   3   Bob  35.0    London  60000.0\n",
            "3   4   NaN   NaN     Paris  55000.0\n",
            "\n",
            "Final Integrated Dataset:\n",
            "   ID  Name   Age      City   Salary\n",
            "0   1  John  25.0   Unknown  55000.0\n",
            "1   2  Jane  30.0  New York  50000.0\n",
            "2   3   Bob  35.0    London  60000.0\n",
            "3   4   NaN   NaN     Paris  55000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-d8eda580c5c4>:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_data['City'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-4-d8eda580c5c4>:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_data['Salary'].fillna(merged_data['Salary'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transformation"
      ],
      "metadata": {
        "id": "pt1r6wrx5zK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Salary': [50000, 60000, 75000, 90000, 100000],\n",
        "    'Experience': [1, 3, 5, 7, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original data:\")\n",
        "print(df)\n",
        "\n",
        "# Standardization (Z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "print(\"\\nStandardized data:\")\n",
        "print(df_standardized)\n",
        "\n",
        "# Min-Max normalization\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_normalized = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "print(\"\\nNormalized data:\")\n",
        "print(df_normalized)\n",
        "\n",
        "# Log transformation (for skewed data)\n",
        "df['Salary_Log'] = np.log(df['Salary'])\n",
        "\n",
        "print(\"\\nData with log-transformed Salary:\")\n",
        "print(df)\n",
        "\n",
        "# Discretization (binning)\n",
        "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 30, 40, 50], labels=['Young', 'Middle', 'Senior'])\n",
        "\n",
        "print(\"\\nData with discretized Age:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l92a5-jr57uo",
        "outputId": "921f1ca3-93aa-4adc-c8f4-3d96b98754ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data:\n",
            "   Age  Salary  Experience\n",
            "0   25   50000           1\n",
            "1   30   60000           3\n",
            "2   35   75000           5\n",
            "3   40   90000           7\n",
            "4   45  100000          10\n",
            "\n",
            "Standardized data:\n",
            "        Age    Salary  Experience\n",
            "0 -1.414214 -1.355815   -1.344387\n",
            "1 -0.707107 -0.813489   -0.704203\n",
            "2  0.000000  0.000000   -0.064018\n",
            "3  0.707107  0.813489    0.576166\n",
            "4  1.414214  1.355815    1.536443\n",
            "\n",
            "Normalized data:\n",
            "    Age  Salary  Experience\n",
            "0  0.00     0.0    0.000000\n",
            "1  0.25     0.2    0.222222\n",
            "2  0.50     0.5    0.444444\n",
            "3  0.75     0.8    0.666667\n",
            "4  1.00     1.0    1.000000\n",
            "\n",
            "Data with log-transformed Salary:\n",
            "   Age  Salary  Experience  Salary_Log\n",
            "0   25   50000           1   10.819778\n",
            "1   30   60000           3   11.002100\n",
            "2   35   75000           5   11.225243\n",
            "3   40   90000           7   11.407565\n",
            "4   45  100000          10   11.512925\n",
            "\n",
            "Data with discretized Age:\n",
            "   Age  Salary  Experience  Salary_Log Age_Group\n",
            "0   25   50000           1   10.819778     Young\n",
            "1   30   60000           3   11.002100     Young\n",
            "2   35   75000           5   11.225243    Middle\n",
            "3   40   90000           7   11.407565    Middle\n",
            "4   45  100000          10   11.512925    Senior\n"
          ]
        }
      ]
    }
  ]
}